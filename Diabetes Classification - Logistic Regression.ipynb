{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83475a85",
   "metadata": {},
   "source": [
    "# Predicting Diabetes - Binary Classifcation\n",
    "Macro F1 score is the evaluation metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e6edf2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6fba14",
   "metadata": {},
   "source": [
    "## Import and Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d35bdb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"diabetes_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e53453d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Id_col = 'Id'\n",
    "target_col = 'diabetes'\n",
    "\n",
    "X = df_train.drop([Id_col, target_col], axis=1)\n",
    "y = df_train[target_col]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08e6bfd",
   "metadata": {},
   "source": [
    "## Train Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27c3f49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce5dd461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipeline with feature engineering transformer and logistic regression\n",
    "pipe = make_pipeline(StandardScaler(),\n",
    "                    LogisticRegression(random_state=42))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc65b70",
   "metadata": {},
   "source": [
    "### Apply KNN Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85e9bcdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45c4777e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make column transformer with KNN imputer\n",
    "imputer_transformer = ColumnTransformer(transformers=[('knnimputer', KNNImputer(missing_values=0),\n",
    "                                              ['plasma_glucose', 'DBP', 'triceps_skin', 'BMI'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6023cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipeline with KNN imputer transformer, scaler, and logistic regression\n",
    "imputer_pipe = make_pipeline(imputer_transformer,\n",
    "                    StandardScaler(),\n",
    "                    LogisticRegression(random_state=42))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764dd2c1",
   "metadata": {},
   "source": [
    "## Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5cab33b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [0.7527, 0.7734, 0.7117, 0.6133, 0.7986]\n",
      "Mean score: 0.7299\n",
      "+/-2 std. dev. range within mean: (0.6001, 0.8597)\n"
     ]
    }
   ],
   "source": [
    "# Cross-validate the model and print the results for non-imputed data\n",
    "cv_scores = cross_val_score(pipe, X_train, y_train, scoring='f1_macro', cv=5)\n",
    "\n",
    "# Calculate mean and standard deviation of scores\n",
    "avg = cv_scores.mean()\n",
    "stddev = cv_scores.std()\n",
    "\n",
    "# Print results\n",
    "print(\"Scores:\", [round(score, 4) for score in cv_scores])\n",
    "print(f\"Mean score: {round(avg, 4)}\")\n",
    "print(f\"+/-2 std. dev. range within mean: ({avg - 2*stddev:.4f}, {avg + 2*stddev:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a194423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [0.7774, 0.7482, 0.6823, 0.6689, 0.7879]\n",
      "Mean score: 0.733\n",
      "+/-2 std. dev. range within mean: (0.6354, 0.8305)\n"
     ]
    }
   ],
   "source": [
    "# Cross-validate the model and print the results for KNN imputed data\n",
    "cv_scores = cross_val_score(imputer_pipe, X_train, y_train, scoring='f1_macro', cv=5)\n",
    "\n",
    "# Calculate mean and standard deviation of scores\n",
    "avg = cv_scores.mean()\n",
    "stddev = cv_scores.std()\n",
    "\n",
    "# Print results\n",
    "print(\"Scores:\", [round(score, 4) for score in cv_scores])\n",
    "print(f\"Mean score: {round(avg, 4)}\")\n",
    "print(f\"+/-2 std. dev. range within mean: ({avg - 2*stddev:.4f}, {avg + 2*stddev:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48cac528",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6ca4db",
   "metadata": {},
   "source": [
    "Hyperparameter tuning knn imputer pipeline since it led to better cross-validation performance.\n",
    "\n",
    "Hyperparameters to tune for logistic regression:\n",
    "\n",
    "* `penalty`: type of regularization used\n",
    "* `C`: regularization strength where making the value smaller increases the strength\n",
    "* `solver`: optimization algorithm used\n",
    "\n",
    "Different solver algorithms used in logistic regression support different sets of penalties. To try different solver hyperparameters without error, a grid is made for:\n",
    "\n",
    "* `'newton-cg', 'lbfgs', 'sag',` and `'saga'` solvers with `'l2'` and `'none'` as the penalties\n",
    "* `'saga'` solver with `'l1'` as the penality\n",
    "* `'liblinear'` solver with `'l1'` and `'l2'` as the penalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d6f5f68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from scipy.stats import uniform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33acacad",
   "metadata": {},
   "source": [
    "### GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "59a8bb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set potential hyperparameter grid for solvers that support 'l2' and 'none' penalities\n",
    "gs_params1 = {'logisticregression__penalty': ('l2', 'none'),\n",
    "          'logisticregression__C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "          'logisticregression__solver': ('newton-cg', 'lbfgs', 'sag', 'saga')}\n",
    "\n",
    "# Set potential hyperparameter grid for saga solver to evaluate how performant model is when penalty='l1'\n",
    "gs_params2 = {'logisticregression__penalty': ['l1'],\n",
    "          'logisticregression__C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "          'logisticregression__solver': ['saga']}\n",
    "\n",
    "# Set potential hyperparameter grid for liblinear solver which support 'l1' and 'l2' penalties\n",
    "gs_params3 = {'logisticregression__penalty': ('l1', 'l2'),\n",
    "          'logisticregression__C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "          'logisticregression__solver': ['liblinear']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ce15f0b",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Marchiano\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('columntransformer',\n",
       "                                        ColumnTransformer(transformers=[('knnimputer',\n",
       "                                                                         KNNImputer(missing_values=0),\n",
       "                                                                         ['plasma_glucose',\n",
       "                                                                          'DBP',\n",
       "                                                                          'triceps_skin',\n",
       "                                                                          'BMI'])])),\n",
       "                                       ('standardscaler', StandardScaler()),\n",
       "                                       ('logisticregression',\n",
       "                                        LogisticRegression(random_state=42))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid=[{'logisticregression__C': [0.001, 0.01, 0.1,...\n",
       "                          'logisticregression__solver': ('newton-cg', 'lbfgs',\n",
       "                                                         'sag', 'saga')},\n",
       "                         {'logisticregression__C': [0.001, 0.01, 0.1, 1, 10,\n",
       "                                                    100, 1000],\n",
       "                          'logisticregression__penalty': ['l1'],\n",
       "                          'logisticregression__solver': ['saga']},\n",
       "                         {'logisticregression__C': [0.001, 0.01, 0.1, 1, 10,\n",
       "                                                    100, 1000],\n",
       "                          'logisticregression__penalty': ('l1', 'l2'),\n",
       "                          'logisticregression__solver': ['liblinear']}],\n",
       "             return_train_score=True, scoring='f1_macro')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform GridSearchCV\n",
    "logit_gs = GridSearchCV(imputer_pipe, param_grid=[gs_params1, gs_params2, gs_params3], \n",
    "                        scoring='f1_macro', cv=5, n_jobs=-1, return_train_score=True)\n",
    "\n",
    "logit_gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "97035520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'logisticregression__C': 0.001, 'logisticregression__penalty': 'none', 'logisticregression__solver': 'newton-cg'}\n",
      "Best Mean Score: 0.7359\n",
      "Best Mean Std. Dev.: 0.0500\n",
      "+/-2 std. dev. range within mean: (0.6358, 0.8360)\n"
     ]
    }
   ],
   "source": [
    "# Print the hyperparameters, score, standard deviation, and standard deviation range of the \n",
    "# best performing model from GridSearchCV\n",
    "\n",
    "avg = logit_gs.best_score_\n",
    "stddev = logit_gs.cv_results_['std_test_score'][logit_gs.best_index_]\n",
    "\n",
    "print(f\"Best Hyperparameters: {logit_gs.best_params_}\")\n",
    "print(f\"Best Mean Score: {avg:.4f}\")\n",
    "print(f\"Best Mean Std. Dev.: {stddev:.4f}\")\n",
    "print(f\"+/-2 std. dev. range within mean: ({avg - 2*stddev:.4f}, {avg + 2*stddev:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4087cc",
   "metadata": {},
   "source": [
    "### RandomSearchCV\n",
    "Randomized search is similar to grid search however, randomly selected values from a continuous distribution will be used for the `C` hyperparameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f3b6f450",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set potential hyperparameter grid for solvers that support 'l2' and 'none' penalities\n",
    "rs_params1 = {'logisticregression__penalty': ('l2', 'none'),\n",
    "          'logisticregression__C': uniform(0.0001, 10000),\n",
    "          'logisticregression__solver': ('newton-cg', 'lbfgs', 'sag', 'saga')}\n",
    "\n",
    "# Set potential hyperparameter grid for saga solver to evaluate how performant model is when penalty='l1'\n",
    "rs_params2 = {'logisticregression__penalty': ['l1'],\n",
    "          'logisticregression__C': uniform(0.0001, 10000),\n",
    "          'logisticregression__solver': ['saga']}\n",
    "\n",
    "# Set potential hyperparameter grid for liblinear solver which support 'l1' and 'l2' penalties\n",
    "rs_params3 = {'logisticregression__penalty': ('l1', 'l2'),\n",
    "          'logisticregression__C': uniform(0.0001, 10000),\n",
    "          'logisticregression__solver': ['liblinear']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "983704cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[('columntransformer',\n",
       "                                              ColumnTransformer(transformers=[('knnimputer',\n",
       "                                                                               KNNImputer(missing_values=0),\n",
       "                                                                               ['plasma_glucose',\n",
       "                                                                                'DBP',\n",
       "                                                                                'triceps_skin',\n",
       "                                                                                'BMI'])])),\n",
       "                                             ('standardscaler',\n",
       "                                              StandardScaler()),\n",
       "                                             ('logisticregression',\n",
       "                                              LogisticRegression(random_state=42))]),\n",
       "                   n_iter=1000, n_jobs=-1,\n",
       "                   param_distributions=[{'logisticregr...\n",
       "                                        {'logisticregression__C': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001922BA68B50>,\n",
       "                                         'logisticregression__penalty': ['l1'],\n",
       "                                         'logisticregression__solver': ['saga']},\n",
       "                                        {'logisticregression__C': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001922BA682B0>,\n",
       "                                         'logisticregression__penalty': ('l1',\n",
       "                                                                         'l2'),\n",
       "                                         'logisticregression__solver': ['liblinear']}],\n",
       "                   return_train_score=True, scoring='f1_macro')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform RandomizedSearchCV \n",
    "logit_rs = RandomizedSearchCV(imputer_pipe, param_distributions=[rs_params1, rs_params2, rs_params3], \n",
    "                              n_iter=1000, scoring='f1_macro', cv=5, n_jobs=-1, return_train_score=True)\n",
    "\n",
    "logit_rs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a211c1dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'logisticregression__C': 6116.223924168812, 'logisticregression__penalty': 'l1', 'logisticregression__solver': 'liblinear'}\n",
      "Best Mean Score: 0.7359\n",
      "Best Mean Std. Dev.: 0.0500\n",
      "+/-2 std. dev. range within mean: (0.6358, 0.8360)\n"
     ]
    }
   ],
   "source": [
    "# Print the hyperparameters, score, standard deviation, and standard deviation range of the \n",
    "# best performing model from RandomSearchCV\n",
    "\n",
    "avg = logit_rs.best_score_\n",
    "stddev = logit_rs.cv_results_['std_test_score'][logit_rs.best_index_]\n",
    "\n",
    "print(f\"Best Hyperparameters: {logit_rs.best_params_}\")\n",
    "print(f\"Best Mean Score: {avg:.4f}\")\n",
    "print(f\"Best Mean Std. Dev.: {stddev:.4f}\")\n",
    "print(f\"+/-2 std. dev. range within mean: ({avg - 2*stddev:.4f}, {avg + 2*stddev:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d8b1e1",
   "metadata": {},
   "source": [
    "## Evaluate on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "79d23123",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "93723f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.90      0.87        81\n",
      "           1       0.72      0.60      0.66        35\n",
      "\n",
      "    accuracy                           0.81       116\n",
      "   macro avg       0.78      0.75      0.76       116\n",
      "weighted avg       0.80      0.81      0.80       116\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = logit_rs.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
